{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "352f8462",
   "metadata": {},
   "source": [
    "Deep Learning\n",
    "- Feature engineering\n",
    "    - Extract feature automatically (In ML we do feature engg manually (EDA))\n",
    "    - ANN BNN\n",
    "    - GenAI uses DL in the backend\n",
    "    - Benifits over ML\n",
    "        - High accuracy\n",
    "        - Automatic feature learning\n",
    "        - End to End learning\n",
    "        - Scalable than ML\n",
    "        - Handles unstructured data\n",
    "        - Transfer Learning --?\n",
    "        - Versatility\n",
    "    - Disadvantages\n",
    "        - Massive data dependency (Huge data volume)\n",
    "        - Data Bias\n",
    "        - High computational cost\n",
    "        - Long training time\n",
    "        - Explainability and Interpretability and Lack of transperrancy\n",
    "        - Difficult to Generalize\n",
    "        - Complex architecture\n",
    "        - Requires specialized knowldge\n",
    "        - High deplyment cost \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8b51a738",
   "metadata": {},
   "source": [
    "Main componenets of Deep Learning:\n",
    "    -   Artificial Nearual Network (ANN) - Foundation\n",
    "        - Neurons/ Nodes, Weights, Biases, Activation Functions\n",
    "    - Layers - Organizing Layers\n",
    "        - Input layers(1), Hidden layers (0-n), Output Layer(1)\n",
    "        - Increase hidden layer increse accuracy but increase learning time\n",
    "    - Architecture - Specific nw structures (Diff types of Deep learning)\n",
    "        - Convolutional Neural Nw (CNN) - Image/Audio/Video\n",
    "        - Recurrent Neural Nw (RNN) - Sequential data\n",
    "        - Transformers - Used moso of the LLM\n",
    "    - Training Process - How model learns\n",
    "        - Loss Function (Cost function), Optimizers, Backpropogation, Epochs, Batch size\n",
    "    - Regularization Techniques (Preventing Overfitting)\n",
    "        - Dropout\n",
    "        - L1/L2 Regularization\n",
    "        - Easy stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b70cdc6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "89b3a13b",
   "metadata": {},
   "source": [
    "Libraries and Framework\n",
    "    - TensarFlow (Google) ~10 lines for demo (Perform activity in backend)\n",
    "    - PyTorch (Facebook) ~100 lines for one demo (Need to specify activity so can be easy while leaning)\n",
    "    - Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ca8e6d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "45e145cd",
   "metadata": {},
   "source": [
    "When to use which\n",
    "    - Use ML\n",
    "        - Smaller dataset\n",
    "        = Certain predeictions\n",
    "        - Domain experties\n",
    "        - Computation resource limeted\n",
    "    - Use DL\n",
    "        - Very large dataset\n",
    "        - Automatic feature extraction\n",
    "        - Complex data Audio/video/text\n",
    "        - High accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
